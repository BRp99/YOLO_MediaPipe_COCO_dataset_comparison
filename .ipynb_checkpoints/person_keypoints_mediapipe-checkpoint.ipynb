{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "100835b2-72d9-4ebe-94a0-3cbbe6469a0d",
   "metadata": {},
   "source": [
    "# Imports to use COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bc0bfa3-88b6-4d41-b4e6-950a5a21515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "import skimage.io as io\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f370a21-d964-4e5c-91d6-77330fb10602",
   "metadata": {},
   "source": [
    "# Imports to use MediaPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "deddd0f1-cdab-4d11-bd74-4465c5295547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76922596-9bb9-4263-9f49-ff8db9c88a57",
   "metadata": {},
   "source": [
    "# Other imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db20e3b9-832b-423f-a8cc-de7178aa30a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6fe4dc-076f-4828-9163-f6658c3ec671",
   "metadata": {},
   "source": [
    "# Load annotations from COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac8de6de-f777-4deb-a9a5-ed29edc4fb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.61s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataDir = './coco/'\n",
    "dataType = 'val2017'\n",
    "annFile = '{}/annotations/instances_{}.json'.format(dataDir, dataType)\n",
    "coco = COCO(annFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2877d642-2882-4e98-8973-bf61326580b6",
   "metadata": {},
   "source": [
    "# Get diferrent categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e456957a-273b-4d98-9782-698b0913b2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ten_images = []\n",
    "\n",
    "# FRISBEE CATEGORY\n",
    "catIds_frisbee = coco.getCatIds(catNms=['frisbee'])\n",
    "imgIds_frisbee = coco.getImgIds(catIds=catIds_frisbee)[:15]\n",
    "\n",
    "for img_id_frisbee in imgIds_frisbee:\n",
    "    img_info_frisbee = coco.loadImgs(img_id_frisbee)[0]\n",
    "\n",
    "\n",
    "\n",
    "four_image_frisbee = coco.loadImgs(imgIds_frisbee[3])[0]\n",
    "ten_images.append(four_image_frisbee)\n",
    "\n",
    "nine_image_frisbee = coco.loadImgs(imgIds_frisbee[8])[0]\n",
    "ten_images.append(nine_image_frisbee)\n",
    "\n",
    "eleven_image_frisbee = coco.loadImgs(imgIds_frisbee[10])[0]\n",
    "ten_images.append(eleven_image_frisbee)\n",
    "\n",
    "fifteen_image_frisbee = coco.loadImgs(imgIds_frisbee[14])[0]\n",
    "ten_images.append(fifteen_image_frisbee)\n",
    "\n",
    "#print(\"10 IMAGES\", ten_images)\n",
    "\n",
    "FRISBEE_CATEGORY = [four_image_frisbee, nine_image_frisbee, eleven_image_frisbee, fifteen_image_frisbee ]\n",
    "\n",
    "\n",
    "for img_info_frisbee in FRISBEE_CATEGORY:\n",
    "    img_id_frisbee = img_info_frisbee['id']\n",
    "    #print(\"img_id_frisbee\", img_id_frisbee)\n",
    "    annIds = coco.getAnnIds(imgIds=img_id_frisbee, catIds=catIds_frisbee, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    # Add annotations to img_info_frisbee\n",
    "    img_info_frisbee['annotations'] = anns\n",
    "    #print(img_info_frisbee)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "print()\n",
    "\n",
    "# SNOWBOARD CATEGORY\n",
    "catIds_snowboard = coco.getCatIds(catNms=['snowboard'])\n",
    "imgIds_snowboard = coco.getImgIds(catIds=catIds_snowboard)[:15]\n",
    "\n",
    "for img_id_snowboard in imgIds_snowboard:\n",
    "    img_info_snowboard = coco.loadImgs(img_id_snowboard)[0]\n",
    "    \n",
    "\n",
    "\n",
    "one_image_snowboard = coco.loadImgs(imgIds_snowboard[0])[0]\n",
    "ten_images.append(one_image_snowboard)\n",
    "\n",
    "ten_image_snowboard = coco.loadImgs(imgIds_snowboard[9])[0]\n",
    "ten_images.append(ten_image_snowboard)\n",
    "\n",
    "fourteen_image_snowboard = coco.loadImgs(imgIds_snowboard[13])[0]\n",
    "ten_images.append(fourteen_image_snowboard)\n",
    "\n",
    "print()\n",
    "\n",
    "# SKATEBOARD CATEGORY\n",
    "catIds_skateboard = coco.getCatIds(catNms=['skateboard'])\n",
    "imgIds_skateboard = coco.getImgIds(catIds=catIds_skateboard)[:10]\n",
    "\n",
    "for img_id_skateboard in imgIds_skateboard:\n",
    "    img_info_skateboard = coco.loadImgs(img_id_skateboard)[0]\n",
    "    \n",
    "\n",
    "five_image_skateboard = coco.loadImgs(imgIds_skateboard[4])[0]\n",
    "ten_images.append(five_image_skateboard)\n",
    "\n",
    "ten_image_skateboard = coco.loadImgs(imgIds_skateboard[9])[0]\n",
    "ten_images.append(ten_image_skateboard)\n",
    "\n",
    "\n",
    "# BICYCLE CATEGORY\n",
    "catIds_bicycle = coco.getCatIds(catNms=['bicycle'])\n",
    "imgIds_bicycle = coco.getImgIds(catIds=catIds_bicycle)[:22]\n",
    "\n",
    "for img_id_bicycle in imgIds_bicycle:\n",
    "    img_info = coco.loadImgs(img_id_bicycle)[0]\n",
    "\n",
    "\n",
    "twenty_one_image_bicycle = coco.loadImgs(imgIds_bicycle[20])[0]\n",
    "ten_images.append(twenty_one_image_bicycle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3692e96-9a25-49a9-8b88-154b673348a5",
   "metadata": {},
   "source": [
    "# Store 10 images inside 'extracted_images_from_coco'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9b662ca-a9e1-49a2-bfa8-a28f084a22eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_keypoints_list = []\n",
    "\n",
    "output_folder= \"./extracted_images_from_coco\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for i, image_info in enumerate(ten_images):\n",
    "    img_url = image_info['coco_url']\n",
    "\n",
    "    I = io.imread(img_url)\n",
    "    filename = f\"image_{i}.jpg\"\n",
    "    output_path = os.path.join(output_folder, filename)\n",
    "    io.imsave(output_path, I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51ba8d9-4223-4a2d-a0f3-738a872403d5",
   "metadata": {},
   "source": [
    "# Model MediaPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6ed5c5c-40ef-4416-ac18-e57686fd41d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time for image_0.jpg: 0.19503140449523926 seconds \n",
      "Processing time for image_1.jpg: 0.184783935546875 seconds \n",
      "Processing time for image_2.jpg: 0.16367864608764648 seconds \n",
      "Processing time for image_3.jpg: 0.2024838924407959 seconds \n",
      "Processing time for image_4.jpg: 0.20420265197753906 seconds \n",
      "Processing time for image_5.jpg: 0.18665599822998047 seconds \n",
      "Processing time for image_6.jpg: 0.20148158073425293 seconds \n",
      "Processing time for image_7.jpg: 0.1962587833404541 seconds \n",
      "Processing time for image_8.jpg: 0.1806929111480713 seconds \n",
      "Processing time for image_9.jpg: 0.14948725700378418 seconds \n",
      "Average processing time just for 9 images with pose detection: 0.1905855337778727 seconds\n",
      "Total images processed: 9\n",
      "Processing speed: 5.246987954319236 images per second\n"
     ]
    }
   ],
   "source": [
    "media_pipe_images_dir = \"./media_pipe_images_dir\"\n",
    "\n",
    "if not os.path.exists(media_pipe_images_dir):\n",
    "    os.makedirs(media_pipe_images_dir)\n",
    "\n",
    "def detect_pose(image_path):\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# CALCULATE THE TIME IT TAKES THE MODEL TO PROCESS EACH IMAGE (INFERENCE TIME)\n",
    "    \n",
    "    start_time_mp = time.time()\n",
    "    \n",
    "    results = pose.process(image_rgb)\n",
    "\n",
    "    end_time_mp = time.time()\n",
    "\n",
    "    processing_time_mp = end_time_mp - start_time_mp\n",
    "    print(f\"Processing time for {os.path.basename(image_path)}: {processing_time_mp} seconds \")\n",
    "    \n",
    "\n",
    "# GET PREDICTED COORDENATES:\n",
    "    predicted_keypoints = []\n",
    "    if results.pose_landmarks:\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            predicted_keypoints.append((landmark.x, landmark.y))\n",
    "    else:\n",
    "        pass\n",
    "    pose.close()\n",
    "    return predicted_keypoints, processing_time_mp\n",
    "\n",
    "predicted_keypoints_list_mp = []\n",
    "total_processing_time_mp = 0\n",
    "total_images_mp = 0\n",
    "\n",
    "\n",
    "files = filter(lambda file:file.endswith('.jpg'), os.listdir(output_folder))\n",
    "for file in files:\n",
    "    image_file = os.path.join(output_folder, file)\n",
    "    predicted_keypoints, processing_time_mp = detect_pose(image_file)\n",
    "    if predicted_keypoints:\n",
    "        total_processing_time_mp += processing_time_mp\n",
    "        total_images_mp += 1\n",
    "        predicted_keypoints_list_mp.append(predicted_keypoints)\n",
    "\n",
    "# CALCULATE THE AVERAGE PROCESSING TIME\n",
    "\n",
    "if total_images_mp > 0:\n",
    "    average_processing_time = total_processing_time_mp / total_images_mp\n",
    "    print(f\"Average processing time just for {total_images_mp} images with pose detection: {average_processing_time} seconds\")\n",
    "else:\n",
    "    print(\"None image was process.\")\n",
    "\n",
    "# CALCULATE PROCESSING SPEED\n",
    "\n",
    "processing_speed_mp = total_images_mp / total_processing_time_mp if total_processing_time_mp > 0 else 0\n",
    "\n",
    "print(f\"Total images processed: {total_images_mp}\")\n",
    "print(f\"Processing speed: {processing_speed_mp} images per second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8ec6ab-dbd9-47da-b41d-45529ec8f27f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
